{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_Getting_Data\n",
    "\n",
    "This notebook is used to gather data using GiantBomb's api.  \n",
    "* Scrape game names and id's using the `games` endpoint filtered by console\n",
    "* Scrape individual game content for each game from previous scrape\n",
    "    * Want the `description`, `genres`, `themes`, `producers`, `devs`, maybe even the `people` involved\n",
    "* Scrape all user reviews for console\n",
    "    * Want the `score`, `username`, and `content` of review\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, Constants, logging functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'f05d9dbc286a3eb1f52355ea793a3e96c66a347f' #api access key\n",
    "platform = '146'                                 # Only scraping playstation games.  This will be expanded on in the future\n",
    "headers = {'User-agent': 'LookAYoYo\\'s open source recommender system'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are used to write to a log when scraping. \n",
    "# They are useful for estimating percentage completed, recording\n",
    "# errors, and in general moderating how well the scrape is going.\n",
    "def log_init():\n",
    "    with open('log.txt', 'w') as log:\n",
    "            log.write('Beginning Log\\n')\n",
    "def log_write(text):\n",
    "    with open('log.txt', 'a') as log:\n",
    "            log.write(f'{text}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Games\n",
    "* The API can retrieve up to 100 games per request, however to get all the info per game, each game must be requested one at a time.  \n",
    "* This series of functions are to be used to get a preliminary list of game names and their guid called `games_list` for any given platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to get the correct api request url.\n",
    "def getURL(offset = 0):\n",
    "    games_field_list = ['name', 'guid']\n",
    "    games_url = f'https://www.giantbomb.com/api/games/?api_key={key}&format=json&offset={offset}&platforms={platform}&sort=number_of_user_reviews:desc&field_list={\",\".join(games_field_list)}'\n",
    "    return games_url\n",
    "\n",
    "# This function acutally makes the api request and returns its json response\n",
    "def getJsonFromResponse(url):\n",
    "    res = requests.get(url, headers= headers)\n",
    "    soup = BeautifulSoup(res.content, \"lxml\")\n",
    "    json_response = json.loads(soup.find('body').text)\n",
    "    return json_response\n",
    "\n",
    "# This little guy tells us when we've gotten all the data we need.  It will be used in later scrapes as well. \n",
    "def isDone(json_response):\n",
    "    return json_response['number_of_page_results'] + json_response['offset'] > json_response['number_of_total_results']\n",
    "\n",
    "# This is the function to call to get the list. \n",
    "def getAllGames(platform):\n",
    "    '''\n",
    "    Call this function with a given platform id to return a games_list of games from that console and their guid.\n",
    "    '''\n",
    "    log_init()\n",
    "    start=time.time()\n",
    "    flag = True\n",
    "    offset = 0\n",
    "    games_list = []\n",
    "    while flag:\n",
    "        url = getURL(offset)\n",
    "        json_response = getJsonFromResponse(url)\n",
    "        games_list.extend(json_response['results'])\n",
    "        log_write(f'offset = {offset}')\n",
    "        log_write(f'status = {json_response[\"error\"]}')\n",
    "        log_write(f'list_length = {len(games_list)}')\n",
    "        log_write(f'runtime = {time.time() - start} seconds')\n",
    "        if isDone(json_response):\n",
    "            flag = False\n",
    "        else:\n",
    "            offset += 100\n",
    "    return games_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.giantbomb.com/api/games/?api_key=f05d9dbc286a3eb1f52355ea793a3e96c66a347f&format=json&offset=0&platforms=146&sort=number_of_user_reviews:desc&field_list=name,guid\n"
     ]
    }
   ],
   "source": [
    "print(getURL())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we retrieve the `games_list` and save it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_list = getAllGames(platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"games_list.json\", 'w+') as f:\n",
    "    json.dump(games_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game Metadata\n",
    "* Now that we have the list of games to scrape, we can go through one-by-one to get all the metadata we need. \n",
    "* Each game will be saved to its own file as it gets scraped.  Gotta keep that memory available.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the api request url for a given game's guid\n",
    "def getMetaURL(guid):\n",
    "    # The final project only used:\n",
    "    # concepts, developers, genres, themes, publishers\n",
    "    # The other fields were to be used with some potential NLP algorithms that didn't seem relevant\n",
    "    meta_field_list = ['aliases', 'concepts', 'deck', 'developers', \n",
    "                       'franchises', 'genres', 'similar_games',\n",
    "                       'themes', 'description', 'publishers']\n",
    "    meta_url = f'https://www.giantbomb.com/api/game/{guid}/?api_key={key}&format=json&field_list={\",\".join(meta_field_list)}'\n",
    "    return meta_url\n",
    "\n",
    "\n",
    "# Given a request url for a game, this function returns a dictionary of the metadata\n",
    "def getGameMetaData(url):\n",
    "    ret_dict = {}\n",
    "    json_response = getJsonFromResponse(url)\n",
    "    log_write(f'status = {json_response[\"error\"]}')\n",
    "    json_response = json_response['results']\n",
    "    ret_dict['aliases'] = json_response['aliases']\n",
    "    try:\n",
    "        ret_dict['concepts'] = [concept['name'] for concept in json_response['concepts']]\n",
    "    except: \n",
    "        ret_dict['concepts'] = ''\n",
    "    ret_dict['deck'] = json_response['deck']\n",
    "    try:\n",
    "        ret_dict['developers'] = [dev['name'] for dev in json_response['developers']]\n",
    "    except:\n",
    "        ret_dict['developers'] = ''\n",
    "    try:\n",
    "         ret_dict['franchises'] = [franch['name'] for franch in json_response['franchises']]\n",
    "    except:\n",
    "        ret_dict['franchises']=''\n",
    "    try:\n",
    "         ret_dict['publishers'] = [franch['name'] for franch in json_response['publishers']]\n",
    "    except:\n",
    "        ret_dict['publishers']=''\n",
    "    try:\n",
    "        ret_dict['genres'] = [genre['name'] for genre in json_response['genres']]\n",
    "    except:\n",
    "        ret_dict['genres']=''\n",
    "    try:\n",
    "        ret_dict['similar_games'] = [sgame['name'] for sgame in json_response['similar_games']]\n",
    "    except:\n",
    "        ret_dict['similar_games']=''\n",
    "    try:\n",
    "         ret_dict['people'] = [person['name'] for person in json_response['people']]\n",
    "    except:\n",
    "        ret_dict['publishers']=''\n",
    "    try:\n",
    "        ret_dict['themes'] = [theme['name'] for theme in json_response['themes']]\n",
    "    except:\n",
    "         ret_dict['themes'] = ''\n",
    "    ret_dict['description'] = json_response['description']\n",
    "    return ret_dict\n",
    "\n",
    "# This function loops through the games_list and saves a json file of the game's metadata for each game.  \n",
    "def getAllMetaData(games):\n",
    "    log_init()\n",
    "    start=time.time()\n",
    "    #games should just be a list of dictionaries containing guid and name\n",
    "    for i, game in enumerate(games):\n",
    "        guid = game['guid']\n",
    "        name = game['name']\n",
    "        url = getMetaURL(guid)\n",
    "        log_write(f'Game = {name}, {url}')\n",
    "        log_write(f'{100*i/len(games)}%')\n",
    "        metadata = getGameMetaData(url)\n",
    "        metadata.update(game)\n",
    "        log_write(f'runtime = {time.time() - start} seconds')\n",
    "        log_write('')\n",
    "        with open(f'./game_meta_data/meta_data_{metadata[\"guid\"]}.json', 'w') as f:\n",
    "            json.dump(metadata, f)\n",
    "        time.sleep(2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getAllMetaData(games_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
