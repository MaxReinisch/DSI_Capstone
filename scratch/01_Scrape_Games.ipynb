{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, I can get all the game titles and then figure out the url request to get it's individual page, or I can try to scrape the url directly.  I can use the same name scraping to get users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import requests\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "console_name_list = ['xboxone', 'ps4', 'wii-u', 'pc', 'switch', '3ds', 'ios', 'vita']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Get request\n",
    " * Get html from source using BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a logging function for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_init():\n",
    "    with open('log.txt', 'w') as log:\n",
    "            log.write('Beginning Log\\n')\n",
    "def log_write(text):\n",
    "    with open('log.txt', 'a') as log:\n",
    "            log.write(f'{text}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, Run a function that extracts games from the list of games by console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_list(soup):\n",
    "    \n",
    "    ol_of_games = soup.find_all(name=\"li\", attrs={'class': \"game_product\"})\n",
    "\n",
    "    game_dicts = []\n",
    "    for entry in ol_of_games:\n",
    "\n",
    "        game = {}\n",
    "        link = entry.find(\"a\")\n",
    "        critic_score = entry.find(\"div\", attrs={'class': \"metascore_w\"}).text\n",
    "        user_score = entry.find(\"span\", attrs={'class' : 'textscore'}).text\n",
    "        game['title'] = link.text.strip()\n",
    "        game['page'] = link.attrs['href']\n",
    "        game['critic_score'] = critic_score\n",
    "        game['user_score'] = user_score\n",
    "        game_dicts.append(game)\n",
    "    return game_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_console(console):\n",
    "    log_init()\n",
    "    game_url = f\"http://www.metacritic.com/browse/games/release-date/available/{console}/metascore?page=0\"\n",
    "    # Using requests now\n",
    "    headers = {'User-agent': 'no this is patrick .1'}\n",
    "    res = requests.get(game_url, headers=headers)\n",
    "    if res.status_code != 200:\n",
    "        print(\"Couldn't reach page\")\n",
    "        return\n",
    "    \n",
    "    # go to the metacritic game page\n",
    "    page_source = res.content\n",
    "    # Get HTML\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    \n",
    "    ## Count number of pages \n",
    "    \n",
    "    try: # Idk if the try exept works.  Do I use catch here?\n",
    "        pagelist = soup.find(\"ul\", attrs={'class': \"pages\"})\n",
    "        num_pages = len(pagelist.find_all(\"li\"))\n",
    "    except:\n",
    "        print(\"couldn't reach url\")\n",
    "        return\n",
    "\n",
    "    cur_page = 0\n",
    "    game_dicts = []\n",
    "    while(cur_page < num_pages):\n",
    "        game_dicts.extend(scrape_list(soup))\n",
    "        cur_page +=1\n",
    "        game_url = f\"http://www.metacritic.com/browse/games/release-date/available/{console}/metascore?page={cur_page}\"\n",
    "        log_write(f'scraping {game_url}')\n",
    "        headers = {'User-agent': f'NOT IGN {cur_page}'}\n",
    "        res = requests.get(game_url, headers=headers)\n",
    "        if res.status_code != 200:\n",
    "        \n",
    "            log_write(f\"Couldn't reach page {cur_page}\")\n",
    "            log_write(f'status_code: {res.status_code}')\n",
    "            print(f\"Couldn't reach page {cur_page}\")\n",
    "            return game_dicts\n",
    "        page_source = res.content\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        \n",
    "    return game_dicts\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Grand Theft Auto V',\n",
       "  'page': '/game/playstation-4/grand-theft-auto-v',\n",
       "  'critic_score': '97',\n",
       "  'user_score': '8.3'},\n",
       " {'title': 'The Last of Us Remastered',\n",
       "  'page': '/game/playstation-4/the-last-of-us-remastered',\n",
       "  'critic_score': '95',\n",
       "  'user_score': '9.1'},\n",
       " {'title': 'God of War',\n",
       "  'page': '/game/playstation-4/god-of-war',\n",
       "  'critic_score': '94',\n",
       "  'user_score': '9.2'},\n",
       " {'title': 'XCOM 2: War of the Chosen',\n",
       "  'page': '/game/playstation-4/xcom-2-war-of-the-chosen',\n",
       "  'critic_score': '94',\n",
       "  'user_score': '6.2'},\n",
       " {'title': 'Persona 5',\n",
       "  'page': '/game/playstation-4/persona-5',\n",
       "  'critic_score': '93',\n",
       "  'user_score': '9.1'},\n",
       " {'title': 'Metal Gear Solid V: The Phantom Pain',\n",
       "  'page': '/game/playstation-4/metal-gear-solid-v-the-phantom-pain',\n",
       "  'critic_score': '93',\n",
       "  'user_score': '8.2'},\n",
       " {'title': \"Uncharted 4: A Thief's End\",\n",
       "  'page': '/game/playstation-4/uncharted-4-a-thiefs-end',\n",
       "  'critic_score': '93',\n",
       "  'user_score': '8.3'},\n",
       " {'title': 'Journey',\n",
       "  'page': '/game/playstation-4/journey',\n",
       "  'critic_score': '92',\n",
       "  'user_score': '8.4'},\n",
       " {'title': 'Bloodborne',\n",
       "  'page': '/game/playstation-4/bloodborne',\n",
       "  'critic_score': '92',\n",
       "  'user_score': '8.9'},\n",
       " {'title': 'Undertale',\n",
       "  'page': '/game/playstation-4/undertale',\n",
       "  'critic_score': '92',\n",
       "  'user_score': '6.4'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps4 = scrape_console(\"ps4\")\n",
    "ps4[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1585"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ps4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding an index field\n",
    "for i in range(len(ps4)):\n",
    "    ps4[i]['GID'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save list of games \n",
    "fields = ps4[0].keys()\n",
    "\n",
    "with open('ps4.csv', 'w') as g:\n",
    "    dw = csv.DictWriter(g, fieldnames=fields)\n",
    "    dw.writeheader()\n",
    "    dw.writerows(ps4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next, Get data about each game by scraping their individual page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_console(console):\n",
    "    log_init()\n",
    "    log_write('Start Extracting metadata from console')\n",
    "    start_time = time.time()\n",
    "    game_list = []\n",
    "    for game in console:\n",
    "        new_game_data = extract_data_from_game(game)\n",
    "        game_list.append(new_game_data)\n",
    "        log_write(f'Runtime: {time.time()-start_time} ')\n",
    "    return game_list\n",
    "\n",
    "\n",
    "def extract_data_from_game(game):\n",
    "    log_write(f'Extracting data from {game[\"title\"]}')\n",
    "    #generate url from game object\n",
    "    url = \"http://www.metacritic.com\" + game['page'] + \"/details\"\n",
    "    \n",
    "    # get page request and soup object\n",
    "    headers = {'User-agent': f'1.{game[\"title\"]}'}\n",
    "    res = requests.get(url, headers=headers)\n",
    "    \n",
    "    log_write(f\"Accessing page at {url} with status_code {res.status_code}\")\n",
    "    \n",
    "    if(res.status_code > 300):\n",
    "        log_write()\n",
    "        return game\n",
    "    \n",
    "    page_source = res.content\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    #Get meta data\n",
    "    return scrape_meta_data(soup)\n",
    "    \n",
    "def scrape_meta_data(soup):\n",
    "    meta = {}\n",
    "    soup.find()\n",
    "    summary_soup = soup.find('div', attrs={'class': 'product_summary'})\n",
    "    product_soup = soup.find('table', attrs={'cellspacing':'0'})\n",
    "\n",
    "    try:\n",
    "        meta['publisher'] = soup.find('li', attrs={'class': 'publisher'}).find('a').text.strip()\n",
    "    except:\n",
    "        meta['publisher'] = None\n",
    "    try:\n",
    "        meta['release_date'] = soup.find('li', attrs={'class': 'release_data'}).find('span', attrs={'class' : 'data'}).text\n",
    "    except:\n",
    "        meta['release_date'] = None\n",
    "    try:\n",
    "        meta['summary'] = summary_soup.find('span', attrs={'class':'data'}).text\n",
    "    except:\n",
    "        meta['summary'] = None\n",
    "    try:\n",
    "        meta['rating'] = product_soup.find(text='Rating:').parent.parent.find('td').text\n",
    "    except:\n",
    "        meta['rating'] = None\n",
    "    try:\n",
    "        meta['developer'] = product_soup.find(text='Developer:').parent.parent.find('td').text\n",
    "    except:\n",
    "        meta['developer'] = None\n",
    "    try:\n",
    "        meta['genres'] = product_soup.find(text='Genre(s):').parent.parent.find('td').text.strip().replace(\"  \", \"\")\n",
    "    except:\n",
    "        meta['genres'] = None\n",
    "    try:\n",
    "        meta['online'] = (product_soup.find(text='Number of Online Players:').parent.parent.find('td').text == 'No Online Multiplayer')*1\n",
    "    except:\n",
    "        meta['online'] = None\n",
    "    try:\n",
    "        meta['num_credits'] = len(soup.find('table', attrs={'class':'credits'}).find_all('tr'))-1\n",
    "    except:\n",
    "        meta['num_credits'] = None\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ps4 = extract_data_from_console(ps4)\n",
    "\n",
    "for g1, g2 in zip(ps4, new_ps4):\n",
    "    g1.update(g2)\n",
    "\n",
    "ps4[0:20]\n",
    "\n",
    "fields = ps4[0].keys()\n",
    "\n",
    "with open('ps4.csv', 'w') as g:\n",
    "    dw = csv.DictWriter(g, fieldnames=fields)\n",
    "    dw.writeheader()\n",
    "    dw.writerows(ps4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
